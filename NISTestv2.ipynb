{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from binNF.normalizing_flows.manager import *\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.multiprocessing as mp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(x):\n",
    "    a=torch.zeros_like(x[:,0])\n",
    "    b=torch.ones_like(x[:,0])\n",
    "   \n",
    "    return torch.where(torch.max(abs(x[:,0]), abs(x[:,1]))>1,a,b)\n",
    "\n",
    "def g(x): #box: expect 0.25 in dim2\n",
    "   \n",
    "    q=torch.max(torch.abs(x),dim=-1).values\n",
    "  \n",
    "    a=torch.zeros_like(q)\n",
    "    b=torch.ones_like(q)\n",
    "   \n",
    "    return torch.where(q<0.5,a,b)\n",
    "\n",
    "def gaussian(x):\n",
    "    return torch.exp( -((x[:,0]-0.5)**2+(x[:,1]-0.5)**2)/(0.3**2)) \n",
    "\n",
    "def camel(x):\n",
    "    return torch.exp( -((x[:,0]-0.75)**2+(x[:,1]-0.75)**2)/(0.2**2))+torch.exp( -((x[:,0]-0.25)**2+(x[:,1]-0.25)**2)/(0.2**2))\n",
    "\n",
    "def gaussianb(x):\n",
    "    return torch.exp( -(x)**2)[:,0]\n",
    "\n",
    "def gaussianbnp(x):\n",
    "    return np.exp( -((x[:,0]+1)**2+(x[:,1])**2) )\n",
    "\n",
    "def gaussiannp(x):\n",
    "    return np.exp( -(x[:,0])**2 )\n",
    "\n",
    "def con(x):\n",
    "    y=torch.empty(x.shape[0])\n",
    "    return y.fill_(5)\n",
    "\n",
    "def sin(x):\n",
    "    return 2+torch.sin(x[:,1])\n",
    "\n",
    "def lin(x):\n",
    "    return 0.2*x[:,0]+0.5\n",
    "\n",
    "def sinnp(x):\n",
    "    return 2+np.sin(x[:,1])\n",
    "\n",
    "def tanp(r):\n",
    "    return (1+((torch.tan((r-0.5)*np.pi))**2))*np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_flow = 2      # number of dimensions\n",
    "\n",
    " \n",
    "# We define our NormalizingFlow object \n",
    "NF =  PWQuadManager(n_flow=n_flow)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#The model is created\n",
    "NF.create_model(n_pass_through=1,n_cells=2, n_bins=15, NN=[8,8,8,8,8,8,8], roll_step=1) \n",
    "optim = torch.optim.Adamax(NF._model.parameters(),lr=0.000405, weight_decay=2.5e-07) \n",
    "\n",
    "\n",
    "#do other improvements, test without cuda, save stuff, CUDA, git, start hypopt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fd9df005379401eb54b8123d3be36df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Loss: 0.000e+00 | Epoch', max=1000.0, style=ProgressStyleâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "history=NF._train_variance_forward_seq(camel,optim,\"./logs/tmp/\",10000,1000,0,True, True,True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss\n",
      "tensor(0.1624, grad_fn=<MeanBackward0>)\n",
      "Epoch of best result\n",
      "368\n",
      "Best loss\n",
      "tensor(0.0476, grad_fn=<MeanBackward0>)\n",
      "Best loss relative\n",
      "tensor(0.2932, grad_fn=<DivBackward0>)\n",
      "Function evaluations\n",
      "3700000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'      \\n#print(NF.model)\\nlosses=[]\\nfor key, value in NF.history.items():\\n    losses.append(value[\"loss\"])\\n\\nfig = plt.figure(figsize=(12, 4))\\na1=fig.add_subplot(131)\\nplt.plot(losses)\\n\\na1.title.set_text(\\'Loss\\')\\na2=fig.add_subplot(132)\\nplt.plot(np.sqrt(np.exp(losses)))\\na2.title.set_text(\\'Standard Deviation\\')\\n\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print('Initial loss')\n",
    "print(NF.int_loss)\n",
    "print('Epoch of best result')\n",
    "print(NF.best_epoch)\n",
    "print('Best loss')\n",
    "print(NF.best_loss)\n",
    "print('Best loss relative')\n",
    "print(NF.best_loss_rel)\n",
    "print('Function evaluations')\n",
    "print(NF.best_func_count)\n",
    "\"\"\"      \n",
    "#print(NF.model)\n",
    "losses=[]\n",
    "for key, value in NF.history.items():\n",
    "    losses.append(value[\"loss\"])\n",
    "\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "a1=fig.add_subplot(131)\n",
    "plt.plot(losses)\n",
    "\n",
    "a1.title.set_text('Loss')\n",
    "a2=fig.add_subplot(132)\n",
    "plt.plot(np.sqrt(np.exp(losses)))\n",
    "a2.title.set_text('Standard Deviation')\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W\n",
      "tensor([[0.8735, 0.8214],\n",
      "        [0.3355, 0.7534],\n",
      "        [0.3476, 0.9583],\n",
      "        [0.6777, 0.0925],\n",
      "        [0.5267, 0.8377],\n",
      "        [0.0271, 0.6551],\n",
      "        [0.2251, 0.5799],\n",
      "        [0.8015, 0.2300],\n",
      "        [0.6072, 0.7349],\n",
      "        [0.7512, 0.8764],\n",
      "        [0.7042, 0.7676],\n",
      "        [0.1980, 0.8055],\n",
      "        [0.2014, 0.2365],\n",
      "        [0.1202, 0.4900],\n",
      "        [0.5486, 0.8155],\n",
      "        [0.2920, 0.0696],\n",
      "        [0.2912, 0.3334],\n",
      "        [0.2302, 0.3249],\n",
      "        [0.1362, 0.2848],\n",
      "        [0.0941, 0.2388],\n",
      "        [0.5034, 0.8582],\n",
      "        [0.4246, 0.2707],\n",
      "        [0.7441, 0.9688],\n",
      "        [0.3914, 0.8287],\n",
      "        [0.7314, 0.9466],\n",
      "        [0.3634, 0.6738],\n",
      "        [0.5428, 0.6822],\n",
      "        [0.9415, 0.6112],\n",
      "        [0.9460, 0.2324],\n",
      "        [0.8106, 0.2091],\n",
      "        [0.9338, 0.6363],\n",
      "        [0.6436, 0.8144],\n",
      "        [0.9323, 0.7901],\n",
      "        [0.3414, 0.5618],\n",
      "        [0.8846, 0.1560],\n",
      "        [0.5221, 0.2339],\n",
      "        [0.4105, 0.2649],\n",
      "        [0.7066, 0.6571],\n",
      "        [0.7210, 0.1155],\n",
      "        [0.1277, 0.2099]])\n",
      "with jacob\n",
      "tensor([[0.8735, 0.8214, 1.0000],\n",
      "        [0.3355, 0.7534, 1.0000],\n",
      "        [0.3476, 0.9583, 1.0000],\n",
      "        [0.6777, 0.0925, 1.0000],\n",
      "        [0.5267, 0.8377, 1.0000],\n",
      "        [0.0271, 0.6551, 1.0000],\n",
      "        [0.2251, 0.5799, 1.0000],\n",
      "        [0.8015, 0.2300, 1.0000],\n",
      "        [0.6072, 0.7349, 1.0000],\n",
      "        [0.7512, 0.8764, 1.0000],\n",
      "        [0.7042, 0.7676, 1.0000],\n",
      "        [0.1980, 0.8055, 1.0000],\n",
      "        [0.2014, 0.2365, 1.0000],\n",
      "        [0.1202, 0.4900, 1.0000],\n",
      "        [0.5486, 0.8155, 1.0000],\n",
      "        [0.2920, 0.0696, 1.0000],\n",
      "        [0.2912, 0.3334, 1.0000],\n",
      "        [0.2302, 0.3249, 1.0000],\n",
      "        [0.1362, 0.2848, 1.0000],\n",
      "        [0.0941, 0.2388, 1.0000],\n",
      "        [0.5034, 0.8582, 1.0000],\n",
      "        [0.4246, 0.2707, 1.0000],\n",
      "        [0.7441, 0.9688, 1.0000],\n",
      "        [0.3914, 0.8287, 1.0000],\n",
      "        [0.7314, 0.9466, 1.0000],\n",
      "        [0.3634, 0.6738, 1.0000],\n",
      "        [0.5428, 0.6822, 1.0000],\n",
      "        [0.9415, 0.6112, 1.0000],\n",
      "        [0.9460, 0.2324, 1.0000],\n",
      "        [0.8106, 0.2091, 1.0000],\n",
      "        [0.9338, 0.6363, 1.0000],\n",
      "        [0.6436, 0.8144, 1.0000],\n",
      "        [0.9323, 0.7901, 1.0000],\n",
      "        [0.3414, 0.5618, 1.0000],\n",
      "        [0.8846, 0.1560, 1.0000],\n",
      "        [0.5221, 0.2339, 1.0000],\n",
      "        [0.4105, 0.2649, 1.0000],\n",
      "        [0.7066, 0.6571, 1.0000],\n",
      "        [0.7210, 0.1155, 1.0000],\n",
      "        [0.1277, 0.2099, 1.0000]])\n",
      "XJ\n",
      "tensor([[ 0.8306,  1.4394,  0.8861],\n",
      "        [ 0.7065,  0.6224,  0.9194],\n",
      "        [ 0.9715,  0.5010,  0.8781],\n",
      "        [ 0.1472,  0.7407,  0.7388],\n",
      "        [ 0.8620,  0.7716,  0.5798],\n",
      "        [ 0.6354,  0.0923,  1.1683],\n",
      "        [ 0.4667,  0.2470,  0.5377],\n",
      "        [ 0.3193,  0.9909,  2.7053],\n",
      "        [ 0.7364,  0.8303,  0.3279],\n",
      "        [ 0.9491,  1.1778,  0.6369],\n",
      "        [ 0.8583,  1.0004,  0.4050],\n",
      "        [ 0.7784,  0.4284,  3.0028],\n",
      "        [ 0.1528,  0.2089,  0.2752],\n",
      "        [ 0.4305,  0.1453,  0.7453],\n",
      "        [ 0.8978,  0.7848,  0.3659],\n",
      "        [ 0.0602,  0.3112,  0.3588],\n",
      "        [ 0.1863,  0.2543,  0.1681],\n",
      "        [ 0.2058,  0.2192,  0.1738],\n",
      "        [ 0.1971,  0.1452,  0.2784],\n",
      "        [ 0.1954,  0.1197,  0.4707],\n",
      "        [ 0.8983,  0.7500,  1.0568],\n",
      "        [ 0.3615,  0.4835,  1.3554],\n",
      "        [ 1.0195,  1.3042,  0.2916],\n",
      "        [ 0.9315,  0.3926,  0.9359],\n",
      "        [ 1.0062,  1.1515,  0.3060],\n",
      "        [ 0.7524,  0.9038,  0.2169],\n",
      "        [ 0.7517,  1.1253,  0.4617],\n",
      "        [ 0.6619,  2.1832,  1.6897],\n",
      "        [ 0.2979,  1.6301, 12.6870],\n",
      "        [ 0.2610,  0.2482,  0.4683],\n",
      "        [ 0.6807,  1.9089,  2.6893],\n",
      "        [ 0.8258,  0.9611,  0.2918],\n",
      "        [ 0.8164,  1.6250,  0.5142],\n",
      "        [ 0.5160,  0.7274,  0.6040],\n",
      "        [ 0.1641,  1.0354,  1.9691],\n",
      "        [ 0.3107,  0.5856,  1.2646],\n",
      "        [ 0.3587,  0.4667,  1.5130],\n",
      "        [ 0.8009,  1.0741,  0.6396],\n",
      "        [ 0.1600,  0.8126,  1.1830],\n",
      "        [ 0.1606,  0.1473,  0.4879]], grad_fn=<CatBackward>)\n",
      "XJ2\n",
      "tensor([[0.8303, 1.4466, 0.8891],\n",
      "        [0.7053, 0.6224, 0.9290],\n",
      "        [0.9702, 0.5059, 0.9187],\n",
      "        [0.1484, 0.7409, 0.7401],\n",
      "        [0.8631, 0.7740, 0.6159],\n",
      "        [0.6348, 0.0904, 1.1468],\n",
      "        [0.4634, 0.2399, 0.5325],\n",
      "        [0.3247, 0.9475, 2.7659],\n",
      "        [0.7362, 0.8340, 0.3455],\n",
      "        [0.9458, 1.1926, 0.6339],\n",
      "        [0.8703, 0.9916, 0.3550],\n",
      "        [0.7762, 0.4346, 3.0711],\n",
      "        [0.1523, 0.2089, 0.2768],\n",
      "        [0.4308, 0.1455, 0.7454],\n",
      "        [0.8959, 0.7897, 0.3888],\n",
      "        [0.0599, 0.3113, 0.3605],\n",
      "        [0.1859, 0.2542, 0.1696],\n",
      "        [0.2052, 0.2189, 0.1743],\n",
      "        [0.1989, 0.1436, 0.2810],\n",
      "        [0.1962, 0.1191, 0.4698],\n",
      "        [0.8982, 0.7544, 1.1206],\n",
      "        [0.3619, 0.4853, 1.3747],\n",
      "        [1.0159, 1.3133, 0.2970],\n",
      "        [0.9203, 0.5479, 0.8982],\n",
      "        [1.0020, 1.1502, 0.3203],\n",
      "        [0.7483, 0.8180, 0.2345],\n",
      "        [0.7518, 1.1344, 0.4375],\n",
      "        [0.6637, 2.1490, 1.1544],\n",
      "        [0.3009, 2.0355, 7.7405],\n",
      "        [0.2632, 0.2358, 0.4672],\n",
      "        [0.6796, 1.8273, 2.2974],\n",
      "        [0.8273, 0.9667, 0.2714],\n",
      "        [0.8149, 1.6368, 0.5179],\n",
      "        [0.5145, 0.7200, 0.6146],\n",
      "        [0.1638, 1.0305, 1.9548],\n",
      "        [0.3120, 0.5510, 1.2687],\n",
      "        [0.3539, 0.4731, 1.4984],\n",
      "        [0.8107, 1.0512, 0.6478],\n",
      "        [0.1597, 0.8100, 1.2029],\n",
      "        [0.1610, 0.1472, 0.4937]], grad_fn=<CatBackward>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nf=gaussian\\nprint(\"f(x)\")\\nprint(f(X))\\n\\n\\nprint(\"fXJ\")\\nprint(torch.mul(f(X), XJ[:, -1]))\\n\\nprint(\"loss without jac\")\\nprint(torch.mean(f(X)**2))\\n\\nprint(\"squared mean\")\\nprint(torch.mean(f(X))**2)\\n\\nprint(\"loss\")\\nprint(torch.mean(torch.mul(f(X), XJ[:, -1])**2))\\n\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "w = torch.empty(40, NF.n_flow)\n",
    "torch.nn.init.uniform_(w)\n",
    "\n",
    "print(\"W\")\n",
    "print(w)\n",
    "                    #print(self.format_input(w).requires_grad)\n",
    "print(\"with jacob\")                  # Output a sample of (phase-space point, forward Jacobian)\n",
    "print(NF.format_input(w,torch.device(\"cpu\")))\n",
    "\n",
    "#print(\"mapped\")\n",
    "#print(NF.format_input(100*torch.tan((w-0.5)*(np.pi))))\n",
    "XJ=NF.model(NF.format_input(w,torch.device(\"cpu\")))\n",
    "\n",
    "\n",
    "                    # Separate the points and their Jacobians:\n",
    "print(\"XJ\")\n",
    "print(XJ)# This sample is fixed, we optimize the Jacobian\n",
    "\n",
    "XJ2=NF.best_model(NF.format_input(w,torch.device(\"cpu\")))\n",
    "\n",
    "\n",
    "                    # Separate the points and their Jacobians:\n",
    "print(\"XJ2\")\n",
    "print(XJ2)\n",
    "\n",
    "\"\"\"\n",
    "f=gaussian\n",
    "print(\"f(x)\")\n",
    "print(f(X))\n",
    "\n",
    "\n",
    "print(\"fXJ\")\n",
    "print(torch.mul(f(X), XJ[:, -1]))\n",
    "\n",
    "print(\"loss without jac\")\n",
    "print(torch.mean(f(X)**2))\n",
    "\n",
    "print(\"squared mean\")\n",
    "print(torch.mean(f(X))**2)\n",
    "\n",
    "print(\"loss\")\n",
    "print(torch.mean(torch.mul(f(X), XJ[:, -1])**2))\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xs = np.linspace(-10,10,100)\n",
    "ys = np.linspace(10,-10,100) # in images the y axis is inverted\n",
    "Xs,Ys = np.meshgrid(xs,ys)\n",
    "zs=gaussianbnp(np.array(list(zip(Xs.reshape(100*100),Ys.reshape(100*100)))).astype(np.float32)).reshape(100,100)\n",
    "plt.imshow(zs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reset\n",
      "W\n",
      "tensor([[0.6108, 0.7451],\n",
      "        [0.3028, 0.2412],\n",
      "        [0.2823, 0.1151],\n",
      "        ...,\n",
      "        [0.5725, 0.1838],\n",
      "        [0.8225, 0.9309],\n",
      "        [0.1988, 0.2423]], requires_grad=True)\n",
      "with jacob\n",
      "tensor([[0.6108, 0.7451, 1.0000],\n",
      "        [0.3028, 0.2412, 1.0000],\n",
      "        [0.2823, 0.1151, 1.0000],\n",
      "        ...,\n",
      "        [0.5725, 0.1838, 1.0000],\n",
      "        [0.8225, 0.9309, 1.0000],\n",
      "        [0.1988, 0.2423, 1.0000]], grad_fn=<CatBackward>)\n",
      "XJ\n",
      "tensor([[0.6108, 0.7238, 0.7407],\n",
      "        [0.3028, 0.2571, 1.1249],\n",
      "        [0.2823, 0.1301, 1.1378],\n",
      "        ...,\n",
      "        [0.5725, 0.1827, 1.4329],\n",
      "        [0.8225, 0.9263, 1.0666],\n",
      "        [0.1988, 0.2883, 0.6346]], grad_fn=<CatBackward>)\n",
      "X\n",
      "tensor([[0.6108, 0.7238],\n",
      "        [0.3028, 0.2571],\n",
      "        [0.2823, 0.1301],\n",
      "        ...,\n",
      "        [0.5725, 0.1827],\n",
      "        [0.8225, 0.9263],\n",
      "        [0.1988, 0.2883]])\n",
      "diff\n",
      "tensor([-0.1342,  0.0616,  0.1672,  ...,  0.3886, -0.1084, -0.0435],\n",
      "       grad_fn=<SubBackward0>)\n",
      "f(x)\n",
      "tensor([2.6622, 2.2543, 2.1297,  ..., 2.1817, 2.7994, 2.2843])\n",
      "fXJ\n",
      "tensor([1.9718, 2.5359, 2.4232,  ..., 3.1262, 2.9860, 1.4496],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"reset\")\n",
    "NF.create_model(n_pass_through=1,n_cells=1,n_bins=10, nn_width=2, NN=[20,20,20], roll_step=0)\n",
    "\n",
    "w = torch.empty(10000, NF.n_flow, requires_grad=True)\n",
    "torch.nn.init.uniform_(w,0,1)\n",
    "\n",
    "print(\"W\")\n",
    "print(w)\n",
    "                    #print(self.format_input(w).requires_grad)\n",
    "print(\"with jacob\")                  # Output a sample of (phase-space point, forward Jacobian)\n",
    "print(NF.format_input(w))\n",
    "XJ = NF.model(NF.format_input(w))\n",
    "\n",
    "                    # Separate the points and their Jacobians:\n",
    "print(\"XJ\")\n",
    "print(XJ)# This sample is fixed, we optimize the Jacobian\n",
    "X = ((XJ[:, :-1]).detach())\n",
    "print(\"X\")\n",
    "print(X)\n",
    "print(\"diff\")\n",
    "print(X[:,0]-w[:,1])\n",
    "print(\"f(x)\")\n",
    "print(sin(X))\n",
    "\n",
    "print(\"fXJ\")\n",
    "print(torch.mul(sin(X), XJ[:, -1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#a4=fig.add_subplot(143)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter3D(X[:,0],X[:,1],X[:,2])\n",
    "#plt.2d(X[:,0],X[:,1],X[:,2])\n",
    "#ax.set_aspect(aspect=1.)\n",
    "ax.title.set_text('Jacobian after training')\n",
    "ax.tick_params(\n",
    "    axis='both',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom=True,      # ticks along the bottom edge are off\n",
    "    left=True,         # ticks along the top edge are off\n",
    "    labelbottom=True,\n",
    "    labelleft=True)\n",
    "\n",
    "\n",
    "NF.create_model(n_pass_through=1,n_cells=1, nn_width=2, NN=[5], roll_step=1)\n",
    "rcParams['axes.labelpad'] = 800\n",
    "z = torch.empty((10000,2)) \n",
    "torch.nn.init.uniform_(z,0,1)\n",
    "\n",
    "w=NF.format_input(z)\n",
    "X=NF.model(w).data.numpy()\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(211, projection='3d')\n",
    "ax1.scatter3D(X[:,0],X[:,1],X[:,2])\n",
    "#plt.2d(X[:,0],X[:,1],X[:,2])\n",
    "#ax.set_aspect(aspect=1.)\n",
    "ax1.title.set_text('Jacobian before training')\n",
    "ax1.tick_params(\n",
    "    axis='both',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom=True,      # ticks along the bottom edge are off\n",
    "    left=True,         # ticks along the top edge are off\n",
    "    labelbottom=True,\n",
    "    labelleft=True)\n",
    "#ax1.auto_scale_xyz([0.5, 2], [0, 1], [1.55, 1.75])\n",
    "ax1.xaxis._axinfo['label']['space_factor'] = 4.8\n",
    "ax1.zaxis._axinfo['label']['space_factor'] = 8.8\n",
    "rcParams['axes.labelpad'] = 80\n",
    "\n",
    "print(\"\\n\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0423, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "w = torch.empty((12100,2)) \n",
    "torch.nn.init.uniform_(w,0,1)\n",
    "#q = torch.empty((12100,2)) \n",
    "#torch.nn.init.normal_(q,std=10)\n",
    "#z=150*torch.tan((w-0.5)*(np.pi))\n",
    "\n",
    "\n",
    "Y=NF.format_input(w, dev=torch.device(\"cpu\"))\n",
    "X=NF.model(Y)\n",
    "XZ=NF.best_model(Y)\n",
    "#Z=(torch.atan(X)/np.pi+0.5).data.numpy()\n",
    "#print(Z)\n",
    "X=X.data.numpy()\n",
    "XX=XZ.data.numpy()\n",
    "#z=z.data.numpy()\n",
    "#a3=fig.add_subplot(133)\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "a3=fig.add_subplot(121)\n",
    "\n",
    "plt.hist2d(XX[:,0],XX[:,1],bins=25)\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([-0,1]) \n",
    "axes.set_ylim([-0,1])\n",
    "#a3.set_aspect(aspect=1.)\n",
    "\n",
    "\n",
    "a3.title.set_text('Point histogram (PDF)')\n",
    "a3.tick_params(\n",
    "    axis='both',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom=True,      # ticks along the bottom edge are off\n",
    "    left=True,         # ticks along the top edge are off\n",
    "    labelbottom=True,\n",
    "    labelleft=True)\n",
    "\n",
    "\n",
    "#fig = plt.figure(figsize=(6, 6))\n",
    "a4=fig.add_subplot(122)\n",
    "#plt.hist2d(X[:,0],X[:,1],bins=2500)\n",
    "#Q=[[]]\n",
    "#Q=[[-1,-1,-1],[2,2,2]]\n",
    "#Q[:,1]=[,]\n",
    "#Q=np.ones((10,2))\n",
    "#Q[:,0]*=-1\n",
    "plt.hist2d(XX[:,0],XX[:,1],bins=10)\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([-0,1])\n",
    "axes.set_ylim([-0,1])\n",
    "#a3.set_aspect(aspect=1.)\n",
    "\n",
    "\n",
    "a4.title.set_text('Point histogram (PDF)')\n",
    "a4.tick_params(\n",
    "    axis='both',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom=True,      # ticks along the bottom edge are off\n",
    "    left=True,         # ticks along the top edge are off\n",
    "    labelbottom=True,\n",
    "    labelleft=True)\n",
    "\n",
    "\n",
    "\n",
    "f=camel\n",
    "loss=torch.mean((f(XZ[:,:2])*XZ[:,2])**2)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.empty(20, 2)\n",
    "torch.nn.init.normal_(w, std=100)\n",
    "w.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-bc9878977896>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e-7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1e-6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
