{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from nisrep.normalizing_flows.manager import *\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "torch.set_default_dtype(torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  90.1983,  462.9061],\n",
      "        [  95.1634,  -47.9293],\n",
      "        [-182.7555,  477.5595],\n",
      "        ...,\n",
      "        [  54.5957,   78.6481],\n",
      "        [ -33.4138,  119.9316],\n",
      "        [ 520.2395,  -60.5001]])\n",
      "Value of the integral before mapping by CL\n",
      "tensor(22.2136)\n",
      "tensor([ 0.0224,  0.0224, -0.0129,  ...,  0.0224, -0.0129,  0.0224],\n",
      "       grad_fn=<SelectBackward>)\n",
      "Value of the integral after mapping by CL\n",
      "tensor(9.1101, grad_fn=<MeanBackward0>)\n",
      "Value of the integral in gaussian\n",
      "tensor(16.0140)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "def g(x):\n",
    "    return torch.exp(-torch.sum(x**2,axis=-1)) #Vanilla Gaussian\n",
    "\n",
    "def g(x): #ring, expect 0.51 in 2 dim\n",
    "    q=torch.sqrt(torch.sum(x**2,axis=-1))\n",
    "    #print(q)\n",
    "    f=q.clone()\n",
    "    a=torch.zeros_like(q)\n",
    "    b=torch.ones_like(q)\n",
    "    z=torch.where(q>0.45,a,q)\n",
    "    #print(z)\n",
    "    #print(torch.where(z>1,a,b))\n",
    "    return torch.where(z<0.2,a,b)\n",
    "\"\"\"\n",
    "\n",
    "def g(x): #box: expect 16 in dim 2, 64 in dim 3\n",
    "   \n",
    "    q=torch.max(torch.abs(x),dim=-1).values\n",
    "  \n",
    "    a=torch.zeros_like(q)\n",
    "    b=torch.ones_like(q)\n",
    "   \n",
    "    return torch.where(q>2,a,b)\n",
    "\"\"\"\n",
    "def tanp(x):\n",
    "    return 100*(1+((torch.tan((x-0.5)*np.pi))**2))*np.pi   #derivative for jacobian\n",
    "\n",
    "def gaussianp(x):\n",
    "    mu=0\n",
    "    sigma=1\n",
    "    return torch.prod(-((x-mu)*torch.unsqueeze(torch.exp(-torch.sum((x-mu)**2/2*sigma**2,-1))/(np.sqrt(2*np.pi)*sigma**3),dim=-1)),-1)\n",
    "\"\"\"\n",
    "def normal(x,mu, sigma, n_flow):\n",
    "    return (torch.exp(-torch.sum((x-mu)**2/(2*sigma**2),-1)))/(sigma*np.sqrt((2*np.pi)**n_flow))\n",
    "\n",
    "n_flow=2\n",
    "w = torch.empty((50000,n_flow)) \n",
    "torch.nn.init.uniform_(w)\n",
    "v=100*torch.tan((w-0.5)*(np.pi))\n",
    "print(v)\n",
    "print(\"Value of the integral before mapping by CL\")\n",
    "print(torch.mean(torch.mul(g(v),torch.abs(torch.prod(tanp(w),axis=-1)))))\n",
    "#print(torch.var(torch.mul(g(v),torch.prod(tanp(w),axis=-1))))\n",
    "\n",
    "NF =  AffineManager(n_flow=n_flow)\n",
    "NF.create_model(n_pass_through=1,n_cells=1, nn_width=2, NN=[20,20,20], roll_step=1)\n",
    "#print(v)\n",
    "v=NF.model(NF.format_input(v, dev=v.device))\n",
    "jac=v[:,-1]\n",
    "print(jac)\n",
    "v=v[:,:n_flow]\n",
    "\n",
    "mult=torch.mul(g(v),jac)\n",
    "\n",
    "print(\"Value of the integral after mapping by CL\")\n",
    "print(torch.mean(torch.mul(mult,torch.prod(tanp(w),axis=-1))))\n",
    "\n",
    "\n",
    "w = torch.empty((5000000,n_flow)) \n",
    "Z=torch.nn.init.normal_(w,std=1)\n",
    "\n",
    "print(\"Value of the integral in gaussian\")\n",
    "\n",
    "print(torch.mean(g(Z)/(normal(Z,0,1,n_flow)))) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of the integral before mapping by CL\n",
      "tensor(4832.5034)\n",
      "Value of the integral before mapping by CL minus constant\n",
      "tensor(4732.5034)\n",
      "Variance\n",
      "tensor(2.3324e+09)\n",
      "SDEV\n",
      "tensor(48295.2130)\n",
      "Assumed error\n",
      "tensor(96.5904)\n",
      "tensor([1.1683, 0.2377, 0.7982,  ..., 0.9241, 1.0581, 0.8502],\n",
      "       grad_fn=<SelectBackward>)\n",
      "Value of the integral after mapping by CL\n",
      "tensor(4779.9528, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c65591a875104cd784d4671eba60944f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Loss: 0.000e+00 | Epoch', max=500.0, style=ProgressStyle(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f93323b2ab984c8ab2ca1dd137bd1c7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Step', max=5.0, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4748.2377)\n",
      "tensor(168.8080)\n",
      "Result\n",
      "4755.837743784804\n",
      "100.9884531930085\n",
      "Loss reduction\n",
      "tensor(0.5670, grad_fn=<DivBackward0>)\n",
      "Variance reduction\n",
      "tensor(1.1105, grad_fn=<DivBackward0>)\n",
      "Value of the integral after mapping by training\n",
      "tensor(4824.5630, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def g(x): #box: expect 0.25 in dim2, 0,0039 in dim 8, 0,00195 in dim 9\n",
    "   \n",
    "    q=torch.max(torch.abs(x),dim=-1).values\n",
    "  \n",
    "    a=torch.zeros_like(q)\n",
    "    b=torch.ones_like(q)\n",
    "   \n",
    "    return torch.where(q>0.5,a,b)\n",
    "\n",
    "def gs(x): #box: expect 0.25 in dim2, 0,0039 in dim 8, 0,00195 in dim 9\n",
    "   \n",
    "    q=torch.max(torch.abs(x),dim=-1).values\n",
    "    #s=torch.min(torch.abs(x),dim=-1).values\n",
    "    a=torch.zeros_like(q)\n",
    "    b=torch.ones_like(q)\n",
    "    ret= torch.where(q>0.5,a,b)\n",
    "    sret=torch.where((q>0.6)&(q<0.65),ret,5*b)\n",
    "    return sret\n",
    "\n",
    "def gaussian(x):\n",
    "    return torch.exp( -((x[:,0]-0.5)**2+(x[:,1]-0.5)**2+(x[:,2]-0.5)**2+(x[:,3]-0.5)**2)/(0.05**2)) \n",
    "\n",
    "def gp(x):\n",
    "    #s=100*gaussian(x)\n",
    "    s=(1/((x[:,0]-0.5)**2+0.001**2))\n",
    "    q=(1/((x[:,1])**2+0.001**2))\n",
    "    t=100*torch.ones_like(x[:,0])\n",
    "    return s+t+q\n",
    "    \n",
    "n_flow=2\n",
    "w = torch.empty((250000,n_flow)) \n",
    "torch.nn.init.uniform_(w)\n",
    "\n",
    "print(\"Value of the integral before mapping by CL\")\n",
    "print(torch.mean(gp(w)))\n",
    "print(\"Value of the integral before mapping by CL minus constant\")\n",
    "print(torch.mean(gp(w)-100))\n",
    "print(\"Variance\")\n",
    "print(torch.var(gp(w)))\n",
    "print(\"SDEV\")\n",
    "print(torch.std(gp(w)))\n",
    "print(\"Assumed error\")\n",
    "print(torch.std(gp(w))/np.sqrt(250000))\n",
    "NF =  PWQuadManager(n_flow=n_flow)\n",
    "NF.create_model(n_cells=2, n_bins=10, NN=[10,10,10], dev=torch.device(\"cpu\"))\n",
    "#print(v)\n",
    "v=NF.model(NF.format_input(w,torch.device(\"cpu\")))\n",
    "jac=v[:,-1]\n",
    "print(jac)\n",
    "v=v[:,:n_flow]\n",
    "\n",
    "mult=torch.mul(gp(v),jac)\n",
    "print(\"Value of the integral after mapping by CL\")\n",
    "print(torch.mean(mult))\n",
    "optim = torch.optim.Adamax(NF._model.parameters(),lr=1e-3, weight_decay=1e-5) \n",
    "res,err=NF._train_variance_forward_seq(gp,optim,\"./logs/tmp/\",10000,500,\n",
    "                                           pretty_progressbar=True,save_best=True,run=None,dev=0,log=False,\n",
    "                                               integrate=True,preburn_time=50)\n",
    "print(\"Result\")\n",
    "print(res)\n",
    "print(err)\n",
    "#print(err/np.sqrt(500))\n",
    "v=NF.best_model(NF.format_input(w,torch.device(\"cpu\")))\n",
    "jac=v[:,-1]\n",
    "#print(jac)\n",
    "v=v[:,:n_flow]\n",
    "mult=torch.mul(gp(v),jac)\n",
    "print(\"Loss reduction\")\n",
    "print(NF.best_loss/NF.int_loss)\n",
    "print(\"Variance reduction\")\n",
    "print(torch.var(mult)/torch.var(gp(w)))\n",
    "print(\"Value of the integral after mapping by training\")\n",
    "print(torch.mean(mult))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "3000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "tensor([0.0924])\n",
      "Value of the integral before mapping by CL\n",
      "tensor(0.1345)\n"
     ]
    }
   ],
   "source": [
    "n_flow=2\n",
    "w = torch.empty((1000,n_flow)) \n",
    "torch.nn.init.uniform_(w)\n",
    "maxim=torch.max(normal(w,0,1,n_flow))\n",
    "i=0\n",
    "res=0\n",
    "q=0\n",
    "while(i<5000):\n",
    "    q=q+1\n",
    "    w = torch.empty((1,n_flow)) \n",
    "    torch.nn.init.uniform_(w)\n",
    "    w2=torch.empty((1,1))\n",
    "    inter=normal(w,0,1,n_flow)\n",
    "    if(inter/maxim>w2):\n",
    "        res+=inter\n",
    "        i=i+1\n",
    "    if(i%1000==0):\n",
    "        print(i)\n",
    "print((res/5000)*5000/q)\n",
    "\n",
    "print(\"Value of the integral before mapping by CL\")\n",
    "print(torch.mean(normal(w,0,1,n_flow)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.1267],\n",
      "        [1.7229],\n",
      "        [1.4604],\n",
      "        ...,\n",
      "        [1.6648],\n",
      "        [1.7874],\n",
      "        [1.9973]])\n",
      "tensor(4.7065)\n"
     ]
    }
   ],
   "source": [
    "w = torch.empty((120000,1)) \n",
    "torch.nn.init.uniform_(w)\n",
    "z=torch.mean(1+torch.cos((w-0.5)*np.pi)**2)*np.pi#*16*(1.6)**4\n",
    "print(1+torch.cos((w-0.5)*np.pi)**2)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
