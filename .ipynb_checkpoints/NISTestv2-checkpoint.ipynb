{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from binNF.normalizing_flows.manager import *\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.multiprocessing as mp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(x):\n",
    "    a=torch.zeros_like(x[:,0])\n",
    "    b=torch.ones_like(x[:,0])\n",
    "   \n",
    "    return torch.where(torch.max(abs(x[:,0]), abs(x[:,1]))>1,a,b)\n",
    "\n",
    "def g(x): #box: expect 0.25 in dim2\n",
    "   \n",
    "    q=torch.max(torch.abs(x),dim=-1).values\n",
    "  \n",
    "    a=torch.zeros_like(q)\n",
    "    b=torch.ones_like(q)\n",
    "   \n",
    "    return torch.where(q<0.5,a,b)\n",
    "\n",
    "def gaussian(x):\n",
    "    return torch.exp( -((x[:,0]-0.5)**2+(x[:,1]-0.5)**2)/(0.3**2)) \n",
    "\n",
    "def camel(x):\n",
    "    return torch.exp( -((x[:,0]-0.75)**2+(x[:,1]-0.75)**2)/(0.2**2))+torch.exp( -((x[:,0]-0.25)**2+(x[:,1]-0.25)**2)/(0.2**2))\n",
    "\n",
    "def gaussianb(x):\n",
    "    return torch.exp( -(x)**2)[:,0]\n",
    "\n",
    "def gaussianbnp(x):\n",
    "    return np.exp( -((x[:,0]+1)**2+(x[:,1])**2) )\n",
    "\n",
    "def gaussiannp(x):\n",
    "    return np.exp( -(x[:,0])**2 )\n",
    "\n",
    "def con(x):\n",
    "    y=torch.empty(x.shape[0])\n",
    "    return y.fill_(5)\n",
    "\n",
    "def sin(x):\n",
    "    return 2+torch.sin(x[:,1])\n",
    "\n",
    "def lin(x):\n",
    "    return 0.2*x[:,0]+0.5\n",
    "\n",
    "def sinnp(x):\n",
    "    return 2+np.sin(x[:,1])\n",
    "\n",
    "def tanp(r):\n",
    "    return (1+((torch.tan((r-0.5)*np.pi))**2))*np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_flow = 2      # number of dimensions\n",
    "\n",
    " \n",
    "# We define our NormalizingFlow object \n",
    "NF =  PWQuadManager(n_flow=n_flow)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#The model is created\n",
    "NF.create_model(n_pass_through=1,n_cells=2, n_bins=14, NN=[9,9,9,9,9,9,9,9,9,9,9], roll_step=1) \n",
    "optim = torch.optim.Adamax(NF._model.parameters(),lr=0.008836012333631516, weight_decay=2.78e-07) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "w = torch.empty(500, NF.n_flow)\n",
    "torch.nn.init.uniform_(w)\n",
    "XJ = NF.model(NF.format_input(w,dev=torch.device(\"cpu\")))\n",
    "X = (XJ[:, :-1])\n",
    "#print(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch save not possible\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9a1a0b12958410eadc3539ad19cd7a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Loss: 0.000e+00 | Epoch', max=1000.0, style=ProgressStyleâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch save not possible\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history=NF._train_variance_forward_seq(camel,optim,\"./logs/tmp/\",7000,1000,0,True, True,True)\n",
    "\n",
    "\n",
    "#hypop search 1000, choose optimium, investigate variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss\n",
      "tensor(0.1664, grad_fn=<MeanBackward0>)\n",
      "Epoch of best result\n",
      "41\n",
      "Best loss\n",
      "tensor(0.0461, grad_fn=<MeanBackward0>)\n",
      "Best loss relative\n",
      "tensor(0.2773, grad_fn=<DivBackward0>)\n",
      "Function evaluations\n",
      "301000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'      \\n#print(NF.model)\\nlosses=[]\\nfor key, value in NF.history.items():\\n    losses.append(value[\"loss\"])\\n\\nfig = plt.figure(figsize=(12, 4))\\na1=fig.add_subplot(131)\\nplt.plot(losses)\\n\\na1.title.set_text(\\'Loss\\')\\na2=fig.add_subplot(132)\\nplt.plot(np.sqrt(np.exp(losses)))\\na2.title.set_text(\\'Standard Deviation\\')\\n\\n'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print('Initial loss')\n",
    "print(NF.int_loss)\n",
    "print('Epoch of best result')\n",
    "print(NF.best_epoch)\n",
    "print('Best loss')\n",
    "print(NF.best_loss)\n",
    "print('Best loss relative')\n",
    "print(NF.best_loss_rel)\n",
    "print('Function evaluations')\n",
    "print(NF.best_func_count)\n",
    "\"\"\"      \n",
    "#print(NF.model)\n",
    "losses=[]\n",
    "for key, value in NF.history.items():\n",
    "    losses.append(value[\"loss\"])\n",
    "\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "a1=fig.add_subplot(131)\n",
    "plt.plot(losses)\n",
    "\n",
    "a1.title.set_text('Loss')\n",
    "a2=fig.add_subplot(132)\n",
    "plt.plot(np.sqrt(np.exp(losses)))\n",
    "a2.title.set_text('Standard Deviation')\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W\n",
      "tensor([[0.8735, 0.8214],\n",
      "        [0.3355, 0.7534],\n",
      "        [0.3476, 0.9583],\n",
      "        [0.6777, 0.0925],\n",
      "        [0.5267, 0.8377],\n",
      "        [0.0271, 0.6551],\n",
      "        [0.2251, 0.5799],\n",
      "        [0.8015, 0.2300],\n",
      "        [0.6072, 0.7349],\n",
      "        [0.7512, 0.8764],\n",
      "        [0.7042, 0.7676],\n",
      "        [0.1980, 0.8055],\n",
      "        [0.2014, 0.2365],\n",
      "        [0.1202, 0.4900],\n",
      "        [0.5486, 0.8155],\n",
      "        [0.2920, 0.0696],\n",
      "        [0.2912, 0.3334],\n",
      "        [0.2302, 0.3249],\n",
      "        [0.1362, 0.2848],\n",
      "        [0.0941, 0.2388],\n",
      "        [0.5034, 0.8582],\n",
      "        [0.4246, 0.2707],\n",
      "        [0.7441, 0.9688],\n",
      "        [0.3914, 0.8287],\n",
      "        [0.7314, 0.9466],\n",
      "        [0.3634, 0.6738],\n",
      "        [0.5428, 0.6822],\n",
      "        [0.9415, 0.6112],\n",
      "        [0.9460, 0.2324],\n",
      "        [0.8106, 0.2091],\n",
      "        [0.9338, 0.6363],\n",
      "        [0.6436, 0.8144],\n",
      "        [0.9323, 0.7901],\n",
      "        [0.3414, 0.5618],\n",
      "        [0.8846, 0.1560],\n",
      "        [0.5221, 0.2339],\n",
      "        [0.4105, 0.2649],\n",
      "        [0.7066, 0.6571],\n",
      "        [0.7210, 0.1155],\n",
      "        [0.1277, 0.2099]])\n",
      "with jacob\n",
      "tensor([[0.8735, 0.8214, 1.0000],\n",
      "        [0.3355, 0.7534, 1.0000],\n",
      "        [0.3476, 0.9583, 1.0000],\n",
      "        [0.6777, 0.0925, 1.0000],\n",
      "        [0.5267, 0.8377, 1.0000],\n",
      "        [0.0271, 0.6551, 1.0000],\n",
      "        [0.2251, 0.5799, 1.0000],\n",
      "        [0.8015, 0.2300, 1.0000],\n",
      "        [0.6072, 0.7349, 1.0000],\n",
      "        [0.7512, 0.8764, 1.0000],\n",
      "        [0.7042, 0.7676, 1.0000],\n",
      "        [0.1980, 0.8055, 1.0000],\n",
      "        [0.2014, 0.2365, 1.0000],\n",
      "        [0.1202, 0.4900, 1.0000],\n",
      "        [0.5486, 0.8155, 1.0000],\n",
      "        [0.2920, 0.0696, 1.0000],\n",
      "        [0.2912, 0.3334, 1.0000],\n",
      "        [0.2302, 0.3249, 1.0000],\n",
      "        [0.1362, 0.2848, 1.0000],\n",
      "        [0.0941, 0.2388, 1.0000],\n",
      "        [0.5034, 0.8582, 1.0000],\n",
      "        [0.4246, 0.2707, 1.0000],\n",
      "        [0.7441, 0.9688, 1.0000],\n",
      "        [0.3914, 0.8287, 1.0000],\n",
      "        [0.7314, 0.9466, 1.0000],\n",
      "        [0.3634, 0.6738, 1.0000],\n",
      "        [0.5428, 0.6822, 1.0000],\n",
      "        [0.9415, 0.6112, 1.0000],\n",
      "        [0.9460, 0.2324, 1.0000],\n",
      "        [0.8106, 0.2091, 1.0000],\n",
      "        [0.9338, 0.6363, 1.0000],\n",
      "        [0.6436, 0.8144, 1.0000],\n",
      "        [0.9323, 0.7901, 1.0000],\n",
      "        [0.3414, 0.5618, 1.0000],\n",
      "        [0.8846, 0.1560, 1.0000],\n",
      "        [0.5221, 0.2339, 1.0000],\n",
      "        [0.4105, 0.2649, 1.0000],\n",
      "        [0.7066, 0.6571, 1.0000],\n",
      "        [0.7210, 0.1155, 1.0000],\n",
      "        [0.1277, 0.2099, 1.0000]])\n",
      "XJ\n",
      "tensor([[ 0.8306,  1.4394,  0.8861],\n",
      "        [ 0.7065,  0.6224,  0.9194],\n",
      "        [ 0.9715,  0.5010,  0.8781],\n",
      "        [ 0.1472,  0.7407,  0.7388],\n",
      "        [ 0.8620,  0.7716,  0.5798],\n",
      "        [ 0.6354,  0.0923,  1.1683],\n",
      "        [ 0.4667,  0.2470,  0.5377],\n",
      "        [ 0.3193,  0.9909,  2.7053],\n",
      "        [ 0.7364,  0.8303,  0.3279],\n",
      "        [ 0.9491,  1.1778,  0.6369],\n",
      "        [ 0.8583,  1.0004,  0.4050],\n",
      "        [ 0.7784,  0.4284,  3.0028],\n",
      "        [ 0.1528,  0.2089,  0.2752],\n",
      "        [ 0.4305,  0.1453,  0.7453],\n",
      "        [ 0.8978,  0.7848,  0.3659],\n",
      "        [ 0.0602,  0.3112,  0.3588],\n",
      "        [ 0.1863,  0.2543,  0.1681],\n",
      "        [ 0.2058,  0.2192,  0.1738],\n",
      "        [ 0.1971,  0.1452,  0.2784],\n",
      "        [ 0.1954,  0.1197,  0.4707],\n",
      "        [ 0.8983,  0.7500,  1.0568],\n",
      "        [ 0.3615,  0.4835,  1.3554],\n",
      "        [ 1.0195,  1.3042,  0.2916],\n",
      "        [ 0.9315,  0.3926,  0.9359],\n",
      "        [ 1.0062,  1.1515,  0.3060],\n",
      "        [ 0.7524,  0.9038,  0.2169],\n",
      "        [ 0.7517,  1.1253,  0.4617],\n",
      "        [ 0.6619,  2.1832,  1.6897],\n",
      "        [ 0.2979,  1.6301, 12.6870],\n",
      "        [ 0.2610,  0.2482,  0.4683],\n",
      "        [ 0.6807,  1.9089,  2.6893],\n",
      "        [ 0.8258,  0.9611,  0.2918],\n",
      "        [ 0.8164,  1.6250,  0.5142],\n",
      "        [ 0.5160,  0.7274,  0.6040],\n",
      "        [ 0.1641,  1.0354,  1.9691],\n",
      "        [ 0.3107,  0.5856,  1.2646],\n",
      "        [ 0.3587,  0.4667,  1.5130],\n",
      "        [ 0.8009,  1.0741,  0.6396],\n",
      "        [ 0.1600,  0.8126,  1.1830],\n",
      "        [ 0.1606,  0.1473,  0.4879]], grad_fn=<CatBackward>)\n",
      "XJ2\n",
      "tensor([[0.8303, 1.4466, 0.8891],\n",
      "        [0.7053, 0.6224, 0.9290],\n",
      "        [0.9702, 0.5059, 0.9187],\n",
      "        [0.1484, 0.7409, 0.7401],\n",
      "        [0.8631, 0.7740, 0.6159],\n",
      "        [0.6348, 0.0904, 1.1468],\n",
      "        [0.4634, 0.2399, 0.5325],\n",
      "        [0.3247, 0.9475, 2.7659],\n",
      "        [0.7362, 0.8340, 0.3455],\n",
      "        [0.9458, 1.1926, 0.6339],\n",
      "        [0.8703, 0.9916, 0.3550],\n",
      "        [0.7762, 0.4346, 3.0711],\n",
      "        [0.1523, 0.2089, 0.2768],\n",
      "        [0.4308, 0.1455, 0.7454],\n",
      "        [0.8959, 0.7897, 0.3888],\n",
      "        [0.0599, 0.3113, 0.3605],\n",
      "        [0.1859, 0.2542, 0.1696],\n",
      "        [0.2052, 0.2189, 0.1743],\n",
      "        [0.1989, 0.1436, 0.2810],\n",
      "        [0.1962, 0.1191, 0.4698],\n",
      "        [0.8982, 0.7544, 1.1206],\n",
      "        [0.3619, 0.4853, 1.3747],\n",
      "        [1.0159, 1.3133, 0.2970],\n",
      "        [0.9203, 0.5479, 0.8982],\n",
      "        [1.0020, 1.1502, 0.3203],\n",
      "        [0.7483, 0.8180, 0.2345],\n",
      "        [0.7518, 1.1344, 0.4375],\n",
      "        [0.6637, 2.1490, 1.1544],\n",
      "        [0.3009, 2.0355, 7.7405],\n",
      "        [0.2632, 0.2358, 0.4672],\n",
      "        [0.6796, 1.8273, 2.2974],\n",
      "        [0.8273, 0.9667, 0.2714],\n",
      "        [0.8149, 1.6368, 0.5179],\n",
      "        [0.5145, 0.7200, 0.6146],\n",
      "        [0.1638, 1.0305, 1.9548],\n",
      "        [0.3120, 0.5510, 1.2687],\n",
      "        [0.3539, 0.4731, 1.4984],\n",
      "        [0.8107, 1.0512, 0.6478],\n",
      "        [0.1597, 0.8100, 1.2029],\n",
      "        [0.1610, 0.1472, 0.4937]], grad_fn=<CatBackward>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nf=gaussian\\nprint(\"f(x)\")\\nprint(f(X))\\n\\n\\nprint(\"fXJ\")\\nprint(torch.mul(f(X), XJ[:, -1]))\\n\\nprint(\"loss without jac\")\\nprint(torch.mean(f(X)**2))\\n\\nprint(\"squared mean\")\\nprint(torch.mean(f(X))**2)\\n\\nprint(\"loss\")\\nprint(torch.mean(torch.mul(f(X), XJ[:, -1])**2))\\n\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "w = torch.empty(40, NF.n_flow)\n",
    "torch.nn.init.uniform_(w)\n",
    "\n",
    "print(\"W\")\n",
    "print(w)\n",
    "                    #print(self.format_input(w).requires_grad)\n",
    "print(\"with jacob\")                  # Output a sample of (phase-space point, forward Jacobian)\n",
    "print(NF.format_input(w,torch.device(\"cpu\")))\n",
    "\n",
    "#print(\"mapped\")\n",
    "#print(NF.format_input(100*torch.tan((w-0.5)*(np.pi))))\n",
    "XJ=NF.model(NF.format_input(w,torch.device(\"cpu\")))\n",
    "\n",
    "\n",
    "                    # Separate the points and their Jacobians:\n",
    "print(\"XJ\")\n",
    "print(XJ)# This sample is fixed, we optimize the Jacobian\n",
    "\n",
    "XJ2=NF.best_model(NF.format_input(w,torch.device(\"cpu\")))\n",
    "\n",
    "\n",
    "                    # Separate the points and their Jacobians:\n",
    "print(\"XJ2\")\n",
    "print(XJ2)\n",
    "\n",
    "\"\"\"\n",
    "f=gaussian\n",
    "print(\"f(x)\")\n",
    "print(f(X))\n",
    "\n",
    "\n",
    "print(\"fXJ\")\n",
    "print(torch.mul(f(X), XJ[:, -1]))\n",
    "\n",
    "print(\"loss without jac\")\n",
    "print(torch.mean(f(X)**2))\n",
    "\n",
    "print(\"squared mean\")\n",
    "print(torch.mean(f(X))**2)\n",
    "\n",
    "print(\"loss\")\n",
    "print(torch.mean(torch.mul(f(X), XJ[:, -1])**2))\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xs = np.linspace(-10,10,100)\n",
    "ys = np.linspace(10,-10,100) # in images the y axis is inverted\n",
    "Xs,Ys = np.meshgrid(xs,ys)\n",
    "zs=gaussianbnp(np.array(list(zip(Xs.reshape(100*100),Ys.reshape(100*100)))).astype(np.float32)).reshape(100,100)\n",
    "plt.imshow(zs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reset\n",
      "W\n",
      "tensor([[0.6108, 0.7451],\n",
      "        [0.3028, 0.2412],\n",
      "        [0.2823, 0.1151],\n",
      "        ...,\n",
      "        [0.5725, 0.1838],\n",
      "        [0.8225, 0.9309],\n",
      "        [0.1988, 0.2423]], requires_grad=True)\n",
      "with jacob\n",
      "tensor([[0.6108, 0.7451, 1.0000],\n",
      "        [0.3028, 0.2412, 1.0000],\n",
      "        [0.2823, 0.1151, 1.0000],\n",
      "        ...,\n",
      "        [0.5725, 0.1838, 1.0000],\n",
      "        [0.8225, 0.9309, 1.0000],\n",
      "        [0.1988, 0.2423, 1.0000]], grad_fn=<CatBackward>)\n",
      "XJ\n",
      "tensor([[0.6108, 0.7238, 0.7407],\n",
      "        [0.3028, 0.2571, 1.1249],\n",
      "        [0.2823, 0.1301, 1.1378],\n",
      "        ...,\n",
      "        [0.5725, 0.1827, 1.4329],\n",
      "        [0.8225, 0.9263, 1.0666],\n",
      "        [0.1988, 0.2883, 0.6346]], grad_fn=<CatBackward>)\n",
      "X\n",
      "tensor([[0.6108, 0.7238],\n",
      "        [0.3028, 0.2571],\n",
      "        [0.2823, 0.1301],\n",
      "        ...,\n",
      "        [0.5725, 0.1827],\n",
      "        [0.8225, 0.9263],\n",
      "        [0.1988, 0.2883]])\n",
      "diff\n",
      "tensor([-0.1342,  0.0616,  0.1672,  ...,  0.3886, -0.1084, -0.0435],\n",
      "       grad_fn=<SubBackward0>)\n",
      "f(x)\n",
      "tensor([2.6622, 2.2543, 2.1297,  ..., 2.1817, 2.7994, 2.2843])\n",
      "fXJ\n",
      "tensor([1.9718, 2.5359, 2.4232,  ..., 3.1262, 2.9860, 1.4496],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"reset\")\n",
    "NF.create_model(n_pass_through=1,n_cells=1,n_bins=10, nn_width=2, NN=[20,20,20], roll_step=0)\n",
    "\n",
    "w = torch.empty(10000, NF.n_flow, requires_grad=True)\n",
    "torch.nn.init.uniform_(w,0,1)\n",
    "\n",
    "print(\"W\")\n",
    "print(w)\n",
    "                    #print(self.format_input(w).requires_grad)\n",
    "print(\"with jacob\")                  # Output a sample of (phase-space point, forward Jacobian)\n",
    "print(NF.format_input(w))\n",
    "XJ = NF.model(NF.format_input(w))\n",
    "\n",
    "                    # Separate the points and their Jacobians:\n",
    "print(\"XJ\")\n",
    "print(XJ)# This sample is fixed, we optimize the Jacobian\n",
    "X = ((XJ[:, :-1]).detach())\n",
    "print(\"X\")\n",
    "print(X)\n",
    "print(\"diff\")\n",
    "print(X[:,0]-w[:,1])\n",
    "print(\"f(x)\")\n",
    "print(sin(X))\n",
    "\n",
    "print(\"fXJ\")\n",
    "print(torch.mul(sin(X), XJ[:, -1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#a4=fig.add_subplot(143)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter3D(X[:,0],X[:,1],X[:,2])\n",
    "#plt.2d(X[:,0],X[:,1],X[:,2])\n",
    "#ax.set_aspect(aspect=1.)\n",
    "ax.title.set_text('Jacobian after training')\n",
    "ax.tick_params(\n",
    "    axis='both',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom=True,      # ticks along the bottom edge are off\n",
    "    left=True,         # ticks along the top edge are off\n",
    "    labelbottom=True,\n",
    "    labelleft=True)\n",
    "\n",
    "\n",
    "NF.create_model(n_pass_through=1,n_cells=1, nn_width=2, NN=[5], roll_step=1)\n",
    "rcParams['axes.labelpad'] = 800\n",
    "z = torch.empty((10000,2)) \n",
    "torch.nn.init.uniform_(z,0,1)\n",
    "\n",
    "w=NF.format_input(z)\n",
    "X=NF.model(w).data.numpy()\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(211, projection='3d')\n",
    "ax1.scatter3D(X[:,0],X[:,1],X[:,2])\n",
    "#plt.2d(X[:,0],X[:,1],X[:,2])\n",
    "#ax.set_aspect(aspect=1.)\n",
    "ax1.title.set_text('Jacobian before training')\n",
    "ax1.tick_params(\n",
    "    axis='both',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom=True,      # ticks along the bottom edge are off\n",
    "    left=True,         # ticks along the top edge are off\n",
    "    labelbottom=True,\n",
    "    labelleft=True)\n",
    "#ax1.auto_scale_xyz([0.5, 2], [0, 1], [1.55, 1.75])\n",
    "ax1.xaxis._axinfo['label']['space_factor'] = 4.8\n",
    "ax1.zaxis._axinfo['label']['space_factor'] = 8.8\n",
    "rcParams['axes.labelpad'] = 80\n",
    "\n",
    "print(\"\\n\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0997, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "w = torch.empty((12100,2)) \n",
    "torch.nn.init.uniform_(w,0,1)\n",
    "#q = torch.empty((12100,2)) \n",
    "#torch.nn.init.normal_(q,std=10)\n",
    "#z=150*torch.tan((w-0.5)*(np.pi))\n",
    "#model=torch.load('torch',map_location=torch.device('cpu'))\n",
    "#NF.best_model.load_state_dict(model['model_state_dict'])\n",
    "Y=NF.format_input(w, dev=torch.device(\"cpu\"))\n",
    "X=NF.model(Y)\n",
    "XZ=NF.best_model(Y)\n",
    "#Z=(torch.atan(X)/np.pi+0.5).data.numpy()\n",
    "#print(Z)\n",
    "X=X.data.numpy()\n",
    "XX=XZ.data.numpy()\n",
    "#z=z.data.numpy()\n",
    "#a3=fig.add_subplot(133)\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "a3=fig.add_subplot(121)\n",
    "\n",
    "plt.hist2d(XX[:,0],XX[:,1],bins=25)\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([-0,1]) \n",
    "axes.set_ylim([-0,1])\n",
    "#a3.set_aspect(aspect=1.)\n",
    "\n",
    "\n",
    "a3.title.set_text('Point histogram (PDF)')\n",
    "a3.tick_params(\n",
    "    axis='both',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom=True,      # ticks along the bottom edge are off\n",
    "    left=True,         # ticks along the top edge are off\n",
    "    labelbottom=True,\n",
    "    labelleft=True)\n",
    "\n",
    "\n",
    "#fig = plt.figure(figsize=(6, 6))\n",
    "a4=fig.add_subplot(122)\n",
    "#plt.hist2d(X[:,0],X[:,1],bins=2500)\n",
    "#Q=[[]]\n",
    "#Q=[[-1,-1,-1],[2,2,2]]\n",
    "#Q[:,1]=[,]\n",
    "#Q=np.ones((10,2))\n",
    "#Q[:,0]*=-1\n",
    "plt.hist2d(XX[:,0],XX[:,1],bins=10)\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([-0,1])\n",
    "axes.set_ylim([-0,1])\n",
    "#a3.set_aspect(aspect=1.)\n",
    "\n",
    "\n",
    "a4.title.set_text('Point histogram (PDF)')\n",
    "a4.tick_params(\n",
    "    axis='both',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom=True,      # ticks along the bottom edge are off\n",
    "    left=True,         # ticks along the top edge are off\n",
    "    labelbottom=True,\n",
    "    labelleft=True)\n",
    "\n",
    "f=camel\n",
    "\n",
    "w = torch.empty(10800, NF.n_flow)\n",
    "torch.nn.init.uniform_(w)\n",
    "XJ = NF.best_model(NF.format_input(w,dev=torch.device(\"cpu\")))\n",
    "X = (XJ[:, :-1])\n",
    "fXJ = torch.mul(f(X), XJ[:, -1])\n",
    "loss = torch.mean(fXJ**2)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.empty(20, 2)\n",
    "torch.nn.init.normal_(w, std=100)\n",
    "w.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-bc9878977896>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e-7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1e-6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
