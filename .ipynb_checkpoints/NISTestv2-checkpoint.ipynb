{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from binNF.normalizing_flows.manager import *\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.multiprocessing as mp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(x):\n",
    "    a=torch.zeros_like(x[:,0])\n",
    "    b=torch.ones_like(x[:,0])\n",
    "   \n",
    "    return torch.where(torch.max(abs(x[:,0]), abs(x[:,1]))>1,a,b)\n",
    "\n",
    "def g(x): #box: expect 0.25 in dim2\n",
    "   \n",
    "    q=torch.max(torch.abs(x),dim=-1).values\n",
    "  \n",
    "    a=torch.zeros_like(q)\n",
    "    b=torch.ones_like(q)\n",
    "   \n",
    "    return torch.where(q<0.5,a,b)\n",
    "\n",
    "def gaussian(x):\n",
    "    return torch.exp( -((x[:,0]-0.5)**2+(x[:,1]-0.5)**2)/(0.3**2)) \n",
    "\n",
    "def camel(x):\n",
    "    return torch.exp( -((x[:,0]-0.75)**2+(x[:,1]-0.75)**2)/(0.2**2))+torch.exp( -((x[:,0]-0.25)**2+(x[:,1]-0.25)**2)/(0.2**2))\n",
    "\n",
    "def gaussianb(x):\n",
    "    return torch.exp( -(x)**2)[:,0]\n",
    "\n",
    "def gaussianbnp(x):\n",
    "    return np.exp( -((x[:,0]+1)**2+(x[:,1])**2) )\n",
    "\n",
    "def gaussiannp(x):\n",
    "    return np.exp( -(x[:,0])**2 )\n",
    "\n",
    "def con(x):\n",
    "    y=torch.empty(x.shape[0])\n",
    "    return y.fill_(5)\n",
    "\n",
    "def sin(x):\n",
    "    return 2+torch.sin(x[:,1])\n",
    "\n",
    "def lin(x):\n",
    "    return 0.2*x[:,0]+0.5\n",
    "\n",
    "def sinnp(x):\n",
    "    return 2+np.sin(x[:,1])\n",
    "\n",
    "def tanp(r):\n",
    "    return (1+((torch.tan((r-0.5)*np.pi))**2))*np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_flow = 2      # number of dimensions\n",
    "\n",
    "\n",
    "# We define our NormalizingFlow object \n",
    "NF =  PWQuadManager(n_flow=n_flow)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.6094,  1.6042,  2.6551,  4.1275,  4.5456,  6.6686,  8.3134,\n",
      "           9.3798, 10.0828, 10.7315, 11.6785, 12.7606, 13.5620, 14.6743,\n",
      "          17.0316, 18.1266, 18.4907]],\n",
      "\n",
      "        [[ 0.8756,  1.4807,  2.4010,  4.1230,  5.2298,  6.1427,  6.9180,\n",
      "           7.9774,  9.2119,  9.7061, 11.1517, 12.1044, 12.5706, 14.9164,\n",
      "          16.4708, 17.1091, 17.7861]],\n",
      "\n",
      "        [[ 1.0055,  2.3018,  3.6961,  4.9565,  5.6877,  6.3328,  7.8901,\n",
      "           8.9929, 10.0243, 10.8907, 12.1847, 13.2753, 14.2402, 15.4247,\n",
      "          16.8258, 17.7165, 18.2931]],\n",
      "\n",
      "        [[ 0.5109,  1.5362,  2.9961,  4.1853,  4.7695,  6.2229,  8.2111,\n",
      "           8.8808,  9.6032, 10.4980, 11.2037, 11.7800, 12.4349, 13.7621,\n",
      "          15.0188, 15.7870, 16.1354]],\n",
      "\n",
      "        [[ 1.5939,  3.2124,  3.9976,  7.0562,  8.4103,  9.4866, 10.1775,\n",
      "          10.7214, 11.6346, 12.9115, 13.5149, 14.8055, 16.1163, 18.6450,\n",
      "          19.8014, 20.4876, 22.0039]]], grad_fn=<CumsumBackward>)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (17) must match the size of tensor b (15) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-118af6a1d684>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#The model is created\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mNF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_pass_through\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_cells\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_bins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroll_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0moptim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.000625\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6.4e-07\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thesis_code/NIS_rep/binNF/normalizing_flows/manager.py\u001b[0m in \u001b[0;36mcreate_model\u001b[0;34m(self, n_pass_through, n_cells, n_bins, NN, roll_step, **opts)\u001b[0m\n\u001b[1;32m    652\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0;31m# Do one pass forward:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cs231n/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cs231n/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cs231n/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thesis_code/NIS_rep/binNF/normalizing_flows/layers/coupling_cells.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVsum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0mVsum2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mVsum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mVsum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mVsum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0mVnorms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVsum\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mVsum2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m         \u001b[0mV\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mVnorms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (17) must match the size of tensor b (15) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "#The model is created\n",
    "NF.create_model(n_pass_through=1,n_cells=2, n_bins=10, NN=[10,10,10,10,10], roll_step=1)\n",
    "optim = torch.optim.Adamax(NF._model.parameters(),lr=0.000625, weight_decay=6.4e-07) \n",
    "\n",
    "\n",
    "#sacred -> yoshi parameter search\n",
    "#simpler, less nodes: 2d 25/5*10/3e-4 10000; 1d 10/3*10/0.1e-4 20000\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#write a main execution script for terminal\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3616dd7476bb4c188778198fe20131a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Loss: 0.000e+00 | Epoch', max=5000.0, style=ProgressStyle…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "history=NF._train_variance_forward_seq(camel,optim,\"./logs/tmp/\",5000,5000,0,True, True,True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss\n",
      "tensor(0.1616, grad_fn=<MeanBackward0>)\n",
      "Epoch of best result\n",
      "204\n",
      "Best loss\n",
      "tensor(0.0770, grad_fn=<MeanBackward0>)\n",
      "Best loss relative\n",
      "tensor(0.4762, grad_fn=<DivBackward0>)\n",
      "Function evaluations\n",
      "1030000\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'PWLinManager' object has no attribute 'history'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-fb549a6b785e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#print(NF.model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mNF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PWLinManager' object has no attribute 'history'"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Initial loss')\n",
    "print(NF.int_loss)\n",
    "print('Epoch of best result')\n",
    "print(NF.best_epoch)\n",
    "print('Best loss')\n",
    "print(NF.best_loss)\n",
    "print('Best loss relative')\n",
    "print(NF.best_loss_rel)\n",
    "print('Function evaluations')\n",
    "print(NF.best_func_count)\n",
    "\"\"\"      \n",
    "#print(NF.model)\n",
    "losses=[]\n",
    "for key, value in NF.history.items():\n",
    "    losses.append(value[\"loss\"])\n",
    "\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "a1=fig.add_subplot(131)\n",
    "plt.plot(losses)\n",
    "\n",
    "a1.title.set_text('Loss')\n",
    "a2=fig.add_subplot(132)\n",
    "plt.plot(np.sqrt(np.exp(losses)))\n",
    "a2.title.set_text('Standard Deviation')\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W\n",
      "tensor([[0.9545, 0.6099],\n",
      "        [0.5643, 0.0594],\n",
      "        [0.7099, 0.4250],\n",
      "        [0.2709, 0.9295],\n",
      "        [0.6115, 0.2234],\n",
      "        [0.2469, 0.4761],\n",
      "        [0.7792, 0.3722],\n",
      "        [0.2147, 0.3288],\n",
      "        [0.1265, 0.6783],\n",
      "        [0.8870, 0.0293],\n",
      "        [0.6161, 0.7583],\n",
      "        [0.5907, 0.3219],\n",
      "        [0.7610, 0.7628],\n",
      "        [0.6870, 0.4121],\n",
      "        [0.3676, 0.5535],\n",
      "        [0.4117, 0.3510],\n",
      "        [0.8196, 0.9297],\n",
      "        [0.4505, 0.3881],\n",
      "        [0.5073, 0.4701],\n",
      "        [0.6202, 0.6401],\n",
      "        [0.0459, 0.3155],\n",
      "        [0.9211, 0.6948],\n",
      "        [0.4751, 0.1985],\n",
      "        [0.1941, 0.0521],\n",
      "        [0.3370, 0.6689],\n",
      "        [0.8188, 0.7308],\n",
      "        [0.0580, 0.1993],\n",
      "        [0.4211, 0.9837],\n",
      "        [0.5723, 0.3705],\n",
      "        [0.7069, 0.3096],\n",
      "        [0.1764, 0.8649],\n",
      "        [0.2726, 0.3998],\n",
      "        [0.0026, 0.8346],\n",
      "        [0.8788, 0.6822],\n",
      "        [0.1514, 0.0065],\n",
      "        [0.0939, 0.8729],\n",
      "        [0.7401, 0.9208],\n",
      "        [0.7619, 0.6265],\n",
      "        [0.4951, 0.1197],\n",
      "        [0.0716, 0.0323]])\n",
      "with jacob\n",
      "tensor([[0.9545, 0.6099, 1.0000],\n",
      "        [0.5643, 0.0594, 1.0000],\n",
      "        [0.7099, 0.4250, 1.0000],\n",
      "        [0.2709, 0.9295, 1.0000],\n",
      "        [0.6115, 0.2234, 1.0000],\n",
      "        [0.2469, 0.4761, 1.0000],\n",
      "        [0.7792, 0.3722, 1.0000],\n",
      "        [0.2147, 0.3288, 1.0000],\n",
      "        [0.1265, 0.6783, 1.0000],\n",
      "        [0.8870, 0.0293, 1.0000],\n",
      "        [0.6161, 0.7583, 1.0000],\n",
      "        [0.5907, 0.3219, 1.0000],\n",
      "        [0.7610, 0.7628, 1.0000],\n",
      "        [0.6870, 0.4121, 1.0000],\n",
      "        [0.3676, 0.5535, 1.0000],\n",
      "        [0.4117, 0.3510, 1.0000],\n",
      "        [0.8196, 0.9297, 1.0000],\n",
      "        [0.4505, 0.3881, 1.0000],\n",
      "        [0.5073, 0.4701, 1.0000],\n",
      "        [0.6202, 0.6401, 1.0000],\n",
      "        [0.0459, 0.3155, 1.0000],\n",
      "        [0.9211, 0.6948, 1.0000],\n",
      "        [0.4751, 0.1985, 1.0000],\n",
      "        [0.1941, 0.0521, 1.0000],\n",
      "        [0.3370, 0.6689, 1.0000],\n",
      "        [0.8188, 0.7308, 1.0000],\n",
      "        [0.0580, 0.1993, 1.0000],\n",
      "        [0.4211, 0.9837, 1.0000],\n",
      "        [0.5723, 0.3705, 1.0000],\n",
      "        [0.7069, 0.3096, 1.0000],\n",
      "        [0.1764, 0.8649, 1.0000],\n",
      "        [0.2726, 0.3998, 1.0000],\n",
      "        [0.0026, 0.8346, 1.0000],\n",
      "        [0.8788, 0.6822, 1.0000],\n",
      "        [0.1514, 0.0065, 1.0000],\n",
      "        [0.0939, 0.8729, 1.0000],\n",
      "        [0.7401, 0.9208, 1.0000],\n",
      "        [0.7619, 0.6265, 1.0000],\n",
      "        [0.4951, 0.1197, 1.0000],\n",
      "        [0.0716, 0.0323, 1.0000]])\n",
      "XJ\n",
      "tensor([[7.5636e-01, 9.1724e-01, 3.6052e-01],\n",
      "        [9.4393e-02, 3.1828e-01, 4.7983e-01],\n",
      "        [5.2383e-01, 7.1180e-01, 1.2567e+00],\n",
      "        [9.4439e-01, 2.7055e-01, 1.3439e+00],\n",
      "        [2.6108e-01, 2.9154e-01, 2.3679e-01],\n",
      "        [3.6768e-01, 2.3951e-01, 2.4709e-01],\n",
      "        [5.3945e-01, 7.8110e-01, 6.4227e-01],\n",
      "        [2.7830e-01, 1.6800e-01, 3.5131e-01],\n",
      "        [5.6014e-01, 1.4100e-01, 7.5042e-01],\n",
      "        [5.8875e-02, 7.4928e-01, 5.8752e+00],\n",
      "        [7.5090e-01, 7.2659e-01, 1.8021e-01],\n",
      "        [3.3127e-01, 2.8224e-01, 4.3410e-01],\n",
      "        [7.9584e-01, 8.0998e-01, 1.3841e-01],\n",
      "        [4.6914e-01, 5.6305e-01, 1.5332e+00],\n",
      "        [1.4186e-01, 2.4678e-01, 1.4164e-01],\n",
      "        [3.1711e-01, 2.2646e-01, 2.6921e-01],\n",
      "        [9.0065e-01, 8.1750e-01, 1.0302e+00],\n",
      "        [3.5870e-01, 3.2150e-01, 6.2142e-01],\n",
      "        [4.8779e-01, 4.8779e-01, 1.0727e+00],\n",
      "        [6.9526e-01, 7.2156e-01, 2.9248e-01],\n",
      "        [2.3026e-01, 6.3406e-02, 3.1832e-01],\n",
      "        [7.9318e-01, 8.8902e-01, 1.8825e-01],\n",
      "        [2.2157e-01, 2.3687e-01, 2.0594e-01],\n",
      "        [6.3476e-02, 1.5568e-01, 4.9768e-01],\n",
      "        [9.8625e-02, 2.2051e-01, 7.9512e-02],\n",
      "        [7.9181e-01, 8.3103e-01, 1.1721e-01],\n",
      "        [1.6307e-01, 8.7719e-02, 7.7658e-01],\n",
      "        [9.8375e-01, 4.1672e-01, 9.4949e-01],\n",
      "        [3.8439e-01, 4.6806e-01, 5.2260e-01],\n",
      "        [3.7882e-01, 6.0309e-01, 6.6756e-01],\n",
      "        [8.4372e-01, 1.9818e-01, 2.8041e+00],\n",
      "        [2.8249e-01, 1.9102e-01, 2.8160e-01],\n",
      "        [7.2394e-01, 3.1733e-03, 3.9666e+00],\n",
      "        [7.8699e-01, 8.6810e-01, 1.6090e-01],\n",
      "        [8.0616e-03, 1.3270e-01, 6.0073e-01],\n",
      "        [8.5569e-01, 1.1536e-01, 1.3008e+00],\n",
      "        [8.9301e-01, 7.6484e-01, 8.7177e-01],\n",
      "        [7.4096e-01, 8.0866e-01, 1.8070e-01],\n",
      "        [1.5225e-01, 2.8205e-01, 5.0754e-01],\n",
      "        [3.8049e-02, 9.2258e-02, 1.1369e+00]], grad_fn=<CatBackward>)\n",
      "XJ2\n",
      "tensor([[7.4982e-01, 9.2151e-01, 4.0699e-01],\n",
      "        [9.0918e-02, 3.2342e-01, 5.1215e-01],\n",
      "        [5.3634e-01, 7.1905e-01, 1.3854e+00],\n",
      "        [9.4606e-01, 2.4290e-01, 1.1634e+00],\n",
      "        [2.6574e-01, 3.0356e-01, 2.6806e-01],\n",
      "        [3.8097e-01, 2.4425e-01, 3.2605e-01],\n",
      "        [5.3806e-01, 7.7902e-01, 6.7818e-01],\n",
      "        [2.8826e-01, 1.6435e-01, 4.2931e-01],\n",
      "        [5.8617e-01, 1.4107e-01, 8.0086e-01],\n",
      "        [5.3730e-02, 7.7484e-01, 4.6864e+00],\n",
      "        [7.5616e-01, 7.1656e-01, 2.0263e-01],\n",
      "        [3.3065e-01, 3.0041e-01, 4.5943e-01],\n",
      "        [7.9431e-01, 8.0842e-01, 1.4717e-01],\n",
      "        [4.8425e-01, 6.5298e-01, 1.6051e+00],\n",
      "        [1.0611e-01, 2.3248e-01, 1.3097e-01],\n",
      "        [3.1998e-01, 2.3584e-01, 3.1152e-01],\n",
      "        [9.0350e-01, 8.1252e-01, 1.2787e+00],\n",
      "        [3.2731e-01, 2.4728e-01, 2.5567e-01],\n",
      "        [4.8228e-01, 4.6320e-01, 1.0090e+00],\n",
      "        [6.9759e-01, 7.1273e-01, 3.2537e-01],\n",
      "        [2.4883e-01, 5.5899e-02, 3.3376e-01],\n",
      "        [7.8697e-01, 8.9272e-01, 2.1084e-01],\n",
      "        [2.1766e-01, 2.4319e-01, 2.4601e-01],\n",
      "        [6.4430e-02, 1.5427e-01, 5.2173e-01],\n",
      "        [1.0340e-01, 2.1401e-01, 7.7258e-02],\n",
      "        [7.8740e-01, 8.3124e-01, 1.3601e-01],\n",
      "        [1.6875e-01, 8.0397e-02, 7.8592e-01],\n",
      "        [9.8391e-01, 3.8836e-01, 8.2125e-01],\n",
      "        [3.8089e-01, 4.7951e-01, 5.5388e-01],\n",
      "        [3.9301e-01, 6.6762e-01, 7.9741e-01],\n",
      "        [8.5578e-01, 1.7696e-01, 2.1002e+00],\n",
      "        [3.0726e-01, 1.9297e-01, 2.6857e-01],\n",
      "        [7.5767e-01, 3.0301e-03, 3.3337e+00],\n",
      "        [7.7988e-01, 8.7125e-01, 1.9021e-01],\n",
      "        [8.0843e-03, 1.3017e-01, 5.7124e-01],\n",
      "        [8.6590e-01, 1.0377e-01, 1.1922e+00],\n",
      "        [8.9567e-01, 7.4785e-01, 1.0587e+00],\n",
      "        [7.3909e-01, 8.0635e-01, 1.9970e-01],\n",
      "        [1.4615e-01, 2.8321e-01, 4.8772e-01],\n",
      "        [3.8397e-02, 9.0891e-02, 1.1989e+00]], grad_fn=<CatBackward>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nf=gaussian\\nprint(\"f(x)\")\\nprint(f(X))\\n\\n\\nprint(\"fXJ\")\\nprint(torch.mul(f(X), XJ[:, -1]))\\n\\nprint(\"loss without jac\")\\nprint(torch.mean(f(X)**2))\\n\\nprint(\"squared mean\")\\nprint(torch.mean(f(X))**2)\\n\\nprint(\"loss\")\\nprint(torch.mean(torch.mul(f(X), XJ[:, -1])**2))\\n\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "w = torch.empty(40, NF.n_flow)\n",
    "torch.nn.init.uniform_(w)\n",
    "\n",
    "print(\"W\")\n",
    "print(w)\n",
    "                    #print(self.format_input(w).requires_grad)\n",
    "print(\"with jacob\")                  # Output a sample of (phase-space point, forward Jacobian)\n",
    "print(NF.format_input(w))\n",
    "\n",
    "#print(\"mapped\")\n",
    "#print(NF.format_input(100*torch.tan((w-0.5)*(np.pi))))\n",
    "XJ=NF.model(NF.format_input(w))\n",
    "\n",
    "\n",
    "                    # Separate the points and their Jacobians:\n",
    "print(\"XJ\")\n",
    "print(XJ)# This sample is fixed, we optimize the Jacobian\n",
    "\n",
    "XJ2=NF.best_model(NF.format_input(w))\n",
    "\n",
    "\n",
    "                    # Separate the points and their Jacobians:\n",
    "print(\"XJ2\")\n",
    "print(XJ2)\n",
    "\n",
    "\"\"\"\n",
    "f=gaussian\n",
    "print(\"f(x)\")\n",
    "print(f(X))\n",
    "\n",
    "\n",
    "print(\"fXJ\")\n",
    "print(torch.mul(f(X), XJ[:, -1]))\n",
    "\n",
    "print(\"loss without jac\")\n",
    "print(torch.mean(f(X)**2))\n",
    "\n",
    "print(\"squared mean\")\n",
    "print(torch.mean(f(X))**2)\n",
    "\n",
    "print(\"loss\")\n",
    "print(torch.mean(torch.mul(f(X), XJ[:, -1])**2))\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xs = np.linspace(-10,10,100)\n",
    "ys = np.linspace(10,-10,100) # in images the y axis is inverted\n",
    "Xs,Ys = np.meshgrid(xs,ys)\n",
    "zs=gaussianbnp(np.array(list(zip(Xs.reshape(100*100),Ys.reshape(100*100)))).astype(np.float32)).reshape(100,100)\n",
    "plt.imshow(zs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reset\n",
      "W\n",
      "tensor([[0.6108, 0.7451],\n",
      "        [0.3028, 0.2412],\n",
      "        [0.2823, 0.1151],\n",
      "        ...,\n",
      "        [0.5725, 0.1838],\n",
      "        [0.8225, 0.9309],\n",
      "        [0.1988, 0.2423]], requires_grad=True)\n",
      "with jacob\n",
      "tensor([[0.6108, 0.7451, 1.0000],\n",
      "        [0.3028, 0.2412, 1.0000],\n",
      "        [0.2823, 0.1151, 1.0000],\n",
      "        ...,\n",
      "        [0.5725, 0.1838, 1.0000],\n",
      "        [0.8225, 0.9309, 1.0000],\n",
      "        [0.1988, 0.2423, 1.0000]], grad_fn=<CatBackward>)\n",
      "XJ\n",
      "tensor([[0.6108, 0.7238, 0.7407],\n",
      "        [0.3028, 0.2571, 1.1249],\n",
      "        [0.2823, 0.1301, 1.1378],\n",
      "        ...,\n",
      "        [0.5725, 0.1827, 1.4329],\n",
      "        [0.8225, 0.9263, 1.0666],\n",
      "        [0.1988, 0.2883, 0.6346]], grad_fn=<CatBackward>)\n",
      "X\n",
      "tensor([[0.6108, 0.7238],\n",
      "        [0.3028, 0.2571],\n",
      "        [0.2823, 0.1301],\n",
      "        ...,\n",
      "        [0.5725, 0.1827],\n",
      "        [0.8225, 0.9263],\n",
      "        [0.1988, 0.2883]])\n",
      "diff\n",
      "tensor([-0.1342,  0.0616,  0.1672,  ...,  0.3886, -0.1084, -0.0435],\n",
      "       grad_fn=<SubBackward0>)\n",
      "f(x)\n",
      "tensor([2.6622, 2.2543, 2.1297,  ..., 2.1817, 2.7994, 2.2843])\n",
      "fXJ\n",
      "tensor([1.9718, 2.5359, 2.4232,  ..., 3.1262, 2.9860, 1.4496],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"reset\")\n",
    "NF.create_model(n_pass_through=1,n_cells=1,n_bins=10, nn_width=2, NN=[20,20,20], roll_step=0)\n",
    "\n",
    "w = torch.empty(10000, NF.n_flow, requires_grad=True)\n",
    "torch.nn.init.uniform_(w,0,1)\n",
    "\n",
    "print(\"W\")\n",
    "print(w)\n",
    "                    #print(self.format_input(w).requires_grad)\n",
    "print(\"with jacob\")                  # Output a sample of (phase-space point, forward Jacobian)\n",
    "print(NF.format_input(w))\n",
    "XJ = NF.model(NF.format_input(w))\n",
    "\n",
    "                    # Separate the points and their Jacobians:\n",
    "print(\"XJ\")\n",
    "print(XJ)# This sample is fixed, we optimize the Jacobian\n",
    "X = ((XJ[:, :-1]).detach())\n",
    "print(\"X\")\n",
    "print(X)\n",
    "print(\"diff\")\n",
    "print(X[:,0]-w[:,1])\n",
    "print(\"f(x)\")\n",
    "print(sin(X))\n",
    "\n",
    "print(\"fXJ\")\n",
    "print(torch.mul(sin(X), XJ[:, -1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#a4=fig.add_subplot(143)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter3D(X[:,0],X[:,1],X[:,2])\n",
    "#plt.2d(X[:,0],X[:,1],X[:,2])\n",
    "#ax.set_aspect(aspect=1.)\n",
    "ax.title.set_text('Jacobian after training')\n",
    "ax.tick_params(\n",
    "    axis='both',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom=True,      # ticks along the bottom edge are off\n",
    "    left=True,         # ticks along the top edge are off\n",
    "    labelbottom=True,\n",
    "    labelleft=True)\n",
    "\n",
    "\n",
    "NF.create_model(n_pass_through=1,n_cells=1, nn_width=2, NN=[5], roll_step=1)\n",
    "rcParams['axes.labelpad'] = 800\n",
    "z = torch.empty((10000,2)) \n",
    "torch.nn.init.uniform_(z,0,1)\n",
    "\n",
    "w=NF.format_input(z)\n",
    "X=NF.model(w).data.numpy()\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(211, projection='3d')\n",
    "ax1.scatter3D(X[:,0],X[:,1],X[:,2])\n",
    "#plt.2d(X[:,0],X[:,1],X[:,2])\n",
    "#ax.set_aspect(aspect=1.)\n",
    "ax1.title.set_text('Jacobian before training')\n",
    "ax1.tick_params(\n",
    "    axis='both',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom=True,      # ticks along the bottom edge are off\n",
    "    left=True,         # ticks along the top edge are off\n",
    "    labelbottom=True,\n",
    "    labelleft=True)\n",
    "#ax1.auto_scale_xyz([0.5, 2], [0, 1], [1.55, 1.75])\n",
    "ax1.xaxis._axinfo['label']['space_factor'] = 4.8\n",
    "ax1.zaxis._axinfo['label']['space_factor'] = 8.8\n",
    "rcParams['axes.labelpad'] = 80\n",
    "\n",
    "print(\"\\n\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0259, grad_fn=<VarBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "w = torch.empty((12100,2)) \n",
    "torch.nn.init.uniform_(w,0,1)\n",
    "#q = torch.empty((12100,2)) \n",
    "#torch.nn.init.normal_(q,std=10)\n",
    "#z=150*torch.tan((w-0.5)*(np.pi))\n",
    "\n",
    "\n",
    "Y=NF.format_input(w, dev=torch.device(\"cpu\"))\n",
    "X=NF.model(Y)\n",
    "XZ=NF.best_model(Y)\n",
    "#Z=(torch.atan(X)/np.pi+0.5).data.numpy()\n",
    "#print(Z)\n",
    "X=X.data.numpy()\n",
    "XX=XZ.data.numpy()\n",
    "#z=z.data.numpy()\n",
    "#a3=fig.add_subplot(133)\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "a3=fig.add_subplot(121)\n",
    "\n",
    "plt.hist2d(XX[:,0],XX[:,1],bins=25)\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([-0,1]) \n",
    "axes.set_ylim([-0,1])\n",
    "#a3.set_aspect(aspect=1.)\n",
    "\n",
    "\n",
    "a3.title.set_text('Point histogram (PDF)')\n",
    "a3.tick_params(\n",
    "    axis='both',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom=True,      # ticks along the bottom edge are off\n",
    "    left=True,         # ticks along the top edge are off\n",
    "    labelbottom=True,\n",
    "    labelleft=True)\n",
    "\n",
    "\n",
    "#fig = plt.figure(figsize=(6, 6))\n",
    "a4=fig.add_subplot(122)\n",
    "#plt.hist2d(X[:,0],X[:,1],bins=2500)\n",
    "#Q=[[]]\n",
    "#Q=[[-1,-1,-1],[2,2,2]]\n",
    "#Q[:,1]=[,]\n",
    "#Q=np.ones((10,2))\n",
    "#Q[:,0]*=-1\n",
    "plt.hist2d(XX[:,0],XX[:,1],bins=10)\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([-0,1])\n",
    "axes.set_ylim([-0,1])\n",
    "#a3.set_aspect(aspect=1.)\n",
    "\n",
    "\n",
    "a4.title.set_text('Point histogram (PDF)')\n",
    "a4.tick_params(\n",
    "    axis='both',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom=True,      # ticks along the bottom edge are off\n",
    "    left=True,         # ticks along the top edge are off\n",
    "    labelbottom=True,\n",
    "    labelleft=True)\n",
    "\n",
    "\n",
    "\n",
    "f=camel\n",
    "var_acc=torch.var(f(XZ[:,:2])*XZ[:,2])\n",
    "print(var_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 124.0116,   47.9657],\n",
       "        [  -7.4994, -213.4038],\n",
       "        [  67.7636,  -32.0429],\n",
       "        [ -42.4372,  -10.8968],\n",
       "        [ -33.5290,    6.3961],\n",
       "        [  13.0762,  -38.7510],\n",
       "        [  83.4277,  -12.8562],\n",
       "        [ -82.8009,  -22.0921],\n",
       "        [  11.4701,  154.7312],\n",
       "        [-127.1577,  -81.6875],\n",
       "        [  43.4944,   21.7519],\n",
       "        [ 182.8632,   95.6407],\n",
       "        [-137.9283,  -93.3104],\n",
       "        [  41.1783,  103.4374],\n",
       "        [-113.1125,  -20.7664],\n",
       "        [ 101.5151,   29.5386],\n",
       "        [ -55.7257,   81.6997],\n",
       "        [ -72.3741,   35.4625],\n",
       "        [  25.8046,   -1.5254],\n",
       "        [-172.8428,   73.4215]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.empty(20, 2)\n",
    "torch.nn.init.normal_(w, std=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
